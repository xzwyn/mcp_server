 import json from pathlib import Path from typing import Optional

from .requirements_parser import parse_requirements from .cpp_analyzer import analyze_cpp from .tdf_parser import parse_tdf from .mapping import map_testids from .context_builder import build_context from .llm_orchestrator import propose_update from .merger import apply_updates from .reporter import generate_report_md

def orchestrate(csv: str, src: str, tdf: str, out_tdf: str, report: str, mapping_cfg: Optional[str], llm_config: Optional[str], k: int = 3, no_llm: bool = False, backup: bool = True) -> dict: # 1) requirements req_json = parse_requirements(csv, mapping_cfg, "artifacts/cache/requirements.json") # 2) code code_index = analyze_cpp(src, req_json, None, None, "artifacts/cache/code_index.json") # 3) tdf parse parsed_tdf = parse_tdf(tdf, "artifacts/cache/tdf_parsed.json") # 4) mapping mapping_json = map_testids(parsed_tdf, req_json, code_index, "artifacts/mapping/mapping.json") # 5) contexts + proposals mapping = json.loads(Path(mapping_json).read_text(encoding="utf-8")) for tid in mapping.keys(): ctx_path = build_context(tid, mapping_json, req_json, code_index, k, f"artifacts/contexts/TESTID_{tid}.json") propose_update(tid, ctx_path, llm_config, no_llm=no_llm, out_path=f"artifacts/proposals/TESTID_{tid}.json") # 6) merge out_tdf_path, diffs_path = apply_updates(tdf, parsed_tdf, "artifacts/proposals", out_tdf, "artifacts/diffs/diffs.json", backup) # 7) report report_path = generate_report_md("artifacts/proposals", diffs_path, mapping_json, report) return { "requirements": req_json, "codeIndex": code_index, "parsedTdf": parsed_tdf, "mapping": mapping_json, "updatedTdf": out_tdf_path, "diffs": diffs_path, "report": report_path }